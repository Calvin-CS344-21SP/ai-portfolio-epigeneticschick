{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "009-linreg-learner.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGDrEYwktBg0"
      },
      "source": [
        "# `009-linreg-learner`\n",
        "\n",
        "Task: Fit a linear regression by gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7EmIFN1tBg5"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCkBDmGQtBg7"
      },
      "source": [
        "from fastai.vision.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4UMuqSUtBg9"
      },
      "source": [
        "This function will make a `DataLoaders` object out of an arary dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4BAWBsatBg9"
      },
      "source": [
        "def make_dataloaders(x, y_true, splitter, batch_size):\n",
        "    data = L(zip(x, y_true))\n",
        "    train_indices, valid_indices = splitter(data)\n",
        "    return DataLoaders(\n",
        "        DataLoader(data[train_indices], batch_size=batch_size, shuffle=True),\n",
        "        DataLoader(data[valid_indices], batch_size=batch_size)\n",
        "    )   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CUx8z4ktBhD"
      },
      "source": [
        "Here are utility functions to plot the first axis of a dataset and a model's predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r9aKuo4tBhE"
      },
      "source": [
        "def plot_data(x, y): plt.scatter(x[:, 0], y[:, 0], s=1)\n",
        "def plot_model(x, model):\n",
        "    x = torch.sort(x)[0]\n",
        "    y_pred = model(x).detach()\n",
        "    plt.plot(x[:, 0], y_pred[:, 0], 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "972ObwVatBhF"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK8kRvqttBhF"
      },
      "source": [
        "Remember this? Suppose we have a dataset with just a single feature `x` and continuous outcome variable `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VklHHSS-tBhH"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "x = torch.rand(500, 1)\n",
        "noise = torch.rand_like(x) * .5\n",
        "y_true = 4 * x - 1 + noise\n",
        "\n",
        "plot_data(x, y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMAAJilltBhH"
      },
      "source": [
        "Let's fit a line to that!\n",
        "\n",
        "In notebook `006` we manually wrote out `y_pred = weights * x + bias`, and manually took a step that reduced the mean squared error `mse_loss = (y_pred - y_true).pow(2).mean()`. In this notebook, we'll use `nn.Linear` and fastai's `Learner` class.\n",
        "\n",
        "First we'll make a fastai-compatible `DataLoaders` from this dataset. You should know everything you need to understand how this works, but don't worry about it on the first time around."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KTkFj8utBhI"
      },
      "source": [
        "splitter = RandomSplitter(valid_pct=0.2, seed=42)\n",
        "batch_size = 5\n",
        "dataloaders = make_dataloaders(x, y_true, splitter, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtkzTmc-tBhJ"
      },
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJSm8Ps-tBhK"
      },
      "source": [
        "Use the `one_batch` method to inspect one batch of the `train` dataloader. Be sure that you can explain the shapes of everything you see. (Look above to see the `batch_size` that this dataloader uses.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpKNStrGtBhL"
      },
      "source": [
        "batch = ...\n",
        "...\n",
        "X_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8pq2G-UtBhL"
      },
      "source": [
        "y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTH9sci4tBhM"
      },
      "source": [
        "**Fill in the blanks to construct a `model`**:\n",
        "\n",
        "```\n",
        "model = nn.Linear(in_features=..., out_features=..., bias=...)\n",
        "```\n",
        "\n",
        "* For `in_features`, think about the shape of the input data.\n",
        "* For `out_features`, think about the shape of the output data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4BUtlCLtBhN"
      },
      "source": [
        "model = nn.Linear(in_features=..., out_features=..., bias=...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP3gqr9WtBhO"
      },
      "source": [
        "To check that we got it right, **call the `model` with the input data from the example batch**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIQ6k_3-tBhO"
      },
      "source": [
        "y_pred = ...\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAxaIg1LtBhP"
      },
      "source": [
        "Let's look at what the model currently predicts on all the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdLQjQw1tBhT"
      },
      "source": [
        "plot_data(x, y_true)\n",
        "plot_model(x, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA1QLS_XtBhU"
      },
      "source": [
        "Pretty bad, huh? Let's evaluate the error on the batch we got:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulFPTVKktBhV"
      },
      "source": [
        "mse_loss = (y_pred - y_batch).pow(2).mean()\n",
        "mse_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6lvsodctBhV"
      },
      "source": [
        "**Create a `loss_func` by instantiating an `nn.MSELoss`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1zcNULytBhW"
      },
      "source": [
        "loss_func = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTv7Pr5ntBhW"
      },
      "source": [
        "**Evaluate the loss on the  `loss_func` on the example batch.**  Check that the output matches exactly.\n",
        "\n",
        "Note: PyTorch loss functions take inputs, then targets. `sklearn` loss functions (metrics) use the reverse order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J6jYcuQtBhY"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V4q9y_5tBhY"
      },
      "source": [
        "**Construct a `Learner`.**\n",
        "\n",
        "* Use the `dataloaders`, `model`, and `loss_func` constructed above.\n",
        "* Use `SGD` as the `opt_func`.\n",
        "* The default `metric` is fine so you can omit it. (If you want to, you may add Mean Absolute Error (`mae`).)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLnETanxtBhZ"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbFSXNCwtBhZ"
      },
      "source": [
        "**Fit the Learner for 10 epochs at the default learning rate.**\n",
        "\n",
        "Plot the loss when it's finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsL9t5MltBha"
      },
      "source": [
        "...\n",
        "learner.recorder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFfHPDqLtBha"
      },
      "source": [
        "**Now let's look at what the model predicts.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBKu7Us3tBhb"
      },
      "source": [
        "plot_data(x, y_true)\n",
        "plot_model(x, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDHDrC98tBhc"
      },
      "source": [
        "**Not there yet! Try different learning rates in the `learner.fit` to see if you can get it to train to convergence in 10 epochs.**\n",
        "\n",
        "Remember to Restart and Run All to check that you're starting with a clean model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUP_AM9gtBhc"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiuRNVXZtBhc"
      },
      "source": [
        "Inspect the `weight` and `bias` attributes of `model`. How close are they to the ideal values? Explain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9VZCap3tBhd"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM82hdVmtBhd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PTTBz7BtBhe"
      },
      "source": [
        "## Extension (optional)\n",
        "\n",
        "Suppose we rerun this notebook hundreds of times with different random seeds. What is the expected value of the validation loss? \n",
        "\n",
        "Answer this by looking at the way that `y_true` was constructed.\n",
        "\n",
        "(Assume that the model gets enough training data that `weights` and `bias` get exactly the right values. It turns out that this assumption isn't actually needed, but it will make it easier to think about where the error comes from.)"
      ]
    }
  ]
}