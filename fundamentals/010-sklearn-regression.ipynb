{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `010`: Regression in `scikit-learn`\n",
    "\n",
    "Goals:\n",
    "* practice with the `fit` and `predict` interface of sklearn models\n",
    "* Get a visual sense of how different regression models work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import necessary modules: Pandas and NumPy for data wrangling, Matplotlib for plotting, and some sklearn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, log_loss, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the data. We're using a dataset of home sale prices from the Ames, Iowa assessor's database, described in [this paper](http://ww2.amstat.org/publications/jse/v19n3/decock.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames = pd.read_csv('https://github.com/kcarnold/AmesHousing/blob/master/data/ames.csv.gz?raw=true', compression=\"gzip\")\n",
    "ames['price'] = ames[\"Sale_Price\"] / 100_000 # Make `price` be in units of $100k, to be easier to interpret.\n",
    "ames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define some functions to plot the data and models. Since we have latitude and longitude for each home, we can plot this data in 2D with a color for the sale price.\n",
    "\n",
    "(Sorry, you'll just have to imagine there's a map underneath.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data():\n",
    "    # You don't have to know how this function works.\n",
    "    plt.scatter(ames['Longitude'], ames['Latitude'], c=ames[\"price\"], s=.5)\n",
    "    plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\")\n",
    "    plt.colorbar(label=\"Sale Price ($100k)\")\n",
    "plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to predict home price based on *location* (which the realtors assure us is the most important factor anyway). So we'll grab the Latitude and Longitude columns of the data. We'll call that input data `X`, by convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ames[['Longitude', 'Latitude']].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target, called `y` by convention, will be the home price (we'll soon introduce a different *y*, but start with this one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ames['price'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `X` has two axes and thus is written in uppercase; `y` has 1 and thus is written in lowercase. (This is `sklearn` convention; other libraries are less consistent about this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split the data into a `train` and `valid` set (which sklearn calls train-*test*, but that's fine). `random_state` is how `sklearn` specifies the random seed (it's actually slightly more flexible than a seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll verify that the shapes make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function to plot our regression model in \"data space\" (i.e., what it would predict everywhere on the map.\n",
    "\n",
    "This function is pretty customized to our specific use case, though you can get inspiration from it for use in other situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(clf):\n",
    "    # Compute extents\n",
    "    lat_min = ames.Latitude.min()\n",
    "    lat_max = ames.Latitude.max()\n",
    "    lon_min = ames.Longitude.min()\n",
    "    lon_max = ames.Longitude.max()\n",
    "    price_min = ames.price.min()\n",
    "    price_max = ames.price.max()\n",
    "\n",
    "    # Ask the classifier for predictions on a grid\n",
    "    xx, yy = np.meshgrid(np.linspace(lon_min, lon_max, 250), np.linspace(lat_min, lat_max, 250))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    # Show the predictions. Superimpose the original data.\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=.5, cmap=plt.cm.viridis, vmin=price_min, vmax=price_max)\n",
    "    plt.scatter(ames['Longitude'], ames['Latitude'], c=ames[\"price\"], s=1, cmap='viridis', vmin=price_min, vmax=price_max)\n",
    "    plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\")\n",
    "    plt.colorbar(label=\"Sale Price ($100k)\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Linear regression\n",
    "\n",
    "1. Fit a linear regression model (call it `linreg`) to the training set (`X_train`, `y_train`).\n",
    "2. Plot the model's predictions in data space. Describe the result qualitatively.\n",
    "3. Compute the model's predictions on the validation set (call them `y_pred`). What does the model predict for the first house in the validation set? How does that compare with the actual price for that home?\n",
    "4. Compute and show the mean squared error and the mean absolute error for the validation set predictions. You may use the `mean_absolute_error` and `mean_squared_error` functions that were imported from `sklearn.metrics` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit a linear regression model (call it `linreg`) to the training set (`X_train`, `y_train`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression().fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the model's predictions in data space. Describe the result qualitatively**. The code for step is filled in for you because there's not a generic way to do this; our approach here is customized to our particular model and task so you don't have to understand the details of how it works.\n",
    "\n",
    "The important aspect of this step is the qualitative description of how this model compares with the decision tree models used later. So come back and write this description once you've also seen the decision tree model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(linreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the model's predictions on the validation set (call them `y_pred`). What does the model predict for the first house in the validation set? How does that compare with the actual price for that home?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute and show the mean squared error and the mean absolute error for the validation set.**\n",
    "\n",
    "* You may use the `mean_absolute_error` and `mean_squared_error` functions (imported from `sklearn.metrics` above).\n",
    "* Use the predictions you already made above.\n",
    "* Use Shift-TAB or `?` to get the documentation for these functions to ensure you're passing the arguments in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Decision tree regression\n",
    "\n",
    "1. Fit a decision tree model (call it `dtree_reg`) to the training set.\n",
    "2. Repeat steps 2 and 4 from Part A using this model.\n",
    "3. Compare `dtree_reg` with `linreg`. Which is better? How can you tell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit a decision tree model (call it `dtree_reg`) to the training set (`X_train`, `y_train`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_reg = DecisionTreeRegressor()..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat steps 2 and 4**..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(dtree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Random Forest regression\n",
    "\n",
    "1. Fit a random forest regression model to this data.\n",
    "2. Compare its performance quantitatively with the linear regression and decision tree models fit above.\n",
    "3. Compare its data-space plot with the decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit a random forest regression model to this data.** Use the default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare its performance quantitatively with the linear regression and decision tree models fit above.**\n",
    "\n",
    "You might notice differences in the shapes of the boundaries it draws and, if you look more closely, a difference in how the boundaries relate to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(rf_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension\n",
    "\n",
    "*optional*\n",
    "\n",
    "1. Compute the loss on the *training* set for each of these models. Can that help you tell whether the model overfit or not?\n",
    "2. Try using more features in the dataset. How well can you predict the price? Be careful about *categorical* features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
