{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "003-pets-dataloader.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nd7vEpJWUoF"
      },
      "source": [
        "# `003-pets-dataloader`\n",
        "\n",
        "Task: create data loaders for the Pets dataset using the mid-level `DataBlocks` API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM6Fwke9WUoI"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szkE1AhvWUoJ"
      },
      "source": [
        "# setup fastai if needed\n",
        "try: import fastbook\n",
        "except ImportError: import subprocess; subprocess.run(['pip','install','-Uq','fastbook'])\n",
        "\n",
        "# Import fastai code.\n",
        "from fastai.vision.all import *\n",
        "\n",
        "# Set a seed for reproducibility.\n",
        "set_seed(12345, reproducible=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMaj2eDjWUoJ"
      },
      "source": [
        "Load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MjqO_7hWUoJ"
      },
      "source": [
        "path = untar_data(URLs.PETS) / \"images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxtvJ4InWUoK"
      },
      "source": [
        "Sort the image filenames so the ordering is consistent across platforms and runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC-FA7bwWUoK"
      },
      "source": [
        "image_files = sorted(get_image_files(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4-EEyRtWUoK"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiyuzPD5WUoK"
      },
      "source": [
        "Create the cat-vs-dog classifier of notebook `000`, but use the mid-level `DataBlocks` API instead of the high-level `ImageDataLoaders`. To do so:\n",
        "\n",
        "1. Create a `splitter` object that will randomly split the images into a training set and a 20% validation set. Use a random seed of 42 to make results reproducible.\n",
        "2. Show the first few indices from the train and valid sets that result from applying `splitter` to the `image_files` declared above.\n",
        "3. Write a `get_y` function that takes an image file `Path` object and returns `cat` or `dog` accordingly.\n",
        "4. Test your `get_y` function by applying it to the first image in the training set. Load the image file (using `PILImage.create`) and check that the label is correct.\n",
        "5. Create a `DataBlock` using the standard `ImageBlock` and `CategoryBlock`, your `get_y` function, and the `splitter`. Have it transform each item by resizing it to 224 pixels square.\n",
        "6. Create a `DataLoaders` by applying your `DataBlock` to the `image_files`.\n",
        "7. Test your `DataLoaders` by showing a batch of images from the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4YUTAvsWUoK"
      },
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtnsLJcGWUoL"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE4aWeaVWUoL"
      },
      "source": [
        "## Analysis\n",
        "\n",
        "*Answer these questions by inspecting the data loaders you just created. Check that your answers matches the answers you got in notebook `000`.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUNZUVThWUoL"
      },
      "source": [
        "**How many images were in the training set? Validation set?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs9bSGXRWUoL"
      },
      "source": [
        "***How many dogs were there in the dataset? How many cats?***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VThpjHEhWUoL"
      },
      "source": [
        "## Extension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRdI0QzZWUoL"
      },
      "source": [
        "**Use the `.summary` method of your `DataBlock` to show the pipeline of operations that is performed to turn one of the `image_files` into a batch.** (Note that `summary` does *not* return any `DataLoaders`.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U83pZ-x6WUoM"
      },
      "source": [
        "**Call the `.one_batch` method on your fully-constructed validation-set `DataLoader` (hint: `.valid`). Notice that the batch has two parts. Describe briefly what happened to the image file(s) to make each part.**"
      ]
    }
  ]
}